{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "XXz9Mrq2pj0m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Intro To ML Project\n",
        "\n",
        "### Comparing the Performance of Various Classification Algorithms for Classifying Text into Categories\n",
        "___\n",
        "\n",
        "The purpose of this project is to compare the performance of various classification algorithms for classifying text into categories. The classification algorithms include:\n",
        "\n",
        "- Multinomial Naive Bayes\n",
        "- Logistic Regression\n",
        "- Decision Tree\n",
        "- Perceptron\n",
        "- Support Vector Machines"
      ]
    },
    {
      "metadata": {
        "id": "M1m2Q3VKqJw6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from pprint import pprint\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JH8QIF_WpCg-",
        "colab_type": "code",
        "outputId": "dc9cdc0d-7d5a-4619-e811-738a934aac20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Load the twenty_train dataset containing the newsgroup classes\n",
        "categories = ['rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey',]\n",
        "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, categories = categories, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "pprint(list(twenty_train.target_names))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xJZ7DXUhr8iA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Extract Features from Text"
      ]
    },
    {
      "metadata": {
        "id": "nikv2dQjrNve",
        "colab_type": "code",
        "outputId": "1be94153-5b36-4880-c8fb-1285e5d3c3cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Preprocess, filter and remove stopword with Count Vectorizer\n",
        "# And count occurencies of each word\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
        "X_train_counts.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2389, 21540)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "z6rMpRKTpjCD",
        "colab_type": "code",
        "outputId": "b2edab16-004c-4a78-aff9-c830579779a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Use frequencies instead of occurencies as longer documents have higher occurencies than shorter documents\n",
        "tf_transformer = TfidfTransformer()\n",
        "X_train_tf = tf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tf.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2389, 21540)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "GmVMURlwxpp-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's define some useful functions"
      ]
    },
    {
      "metadata": {
        "id": "dzJqbXqdxnJO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Generate a simple plot of the test and training learning curve.\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "             label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Cross-validation score\")\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NV_lmcmpPb85",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_auc_curve(y_test, predicted):\n",
        "  \n",
        "  # Compute ROC curve and ROC AUC for each class\n",
        "  n_classes = 4\n",
        "  fpr = dict()\n",
        "  tpr = dict()\n",
        "  roc_auc = dict()\n",
        "  all_y_test_i = np.array([])\n",
        "  all_y_predict_proba = np.array([])\n",
        "  for i in range(n_classes):\n",
        "      y_test_i = map(lambda x: 1 if x == i else 0, y_test)\n",
        "      all_y_test_i = np.concatenate([all_y_test_i, y_test_i])\n",
        "      all_y_predict_proba = np.concatenate([all_y_predict_proba, y_predict_proba[:, i]])\n",
        "      fpr[i], tpr[i], _ = roc_curve(y_test_i, y_predict_proba[:, i])\n",
        "      roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "  # Compute micro-average ROC curve and ROC area\n",
        "  fpr[\"average\"], tpr[\"average\"], _ = roc_curve(all_y_test_i, all_y_predict_proba)\n",
        "  roc_auc[\"average\"] = auc(fpr[\"average\"], tpr[\"average\"])\n",
        "\n",
        "\n",
        "  # Plot average ROC Curve\n",
        "  plt.figure()\n",
        "  plt.plot(fpr[\"average\"], tpr[\"average\"],\n",
        "           label='Average ROC curve (area = {0:0.2f})'\n",
        "                 ''.format(roc_auc[\"average\"]),\n",
        "           color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "  # Plot each individual ROC curve\n",
        "  for i in range(n_classes):\n",
        "      plt.plot(fpr[i], tpr[i], lw=2,\n",
        "               label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "               ''.format(i, roc_auc[i]))\n",
        "\n",
        "  plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g-G8rAzatABl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Classifiers\n",
        "\n",
        "We start with a Naive Bayes Classifier"
      ]
    },
    {
      "metadata": {
        "id": "0kwuHVgms_Fs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "naive_bayes_clf = MultinomialNB().fit(X_train_tf, twenty_train.target)\n",
        "\n",
        "#plot_learning_curve(naive_bayes_clf, \"Naive Bayes Learning Curve\", X_train_tf, twenty_train.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gUQIqlfNtgpN",
        "colab_type": "code",
        "outputId": "e17dbce9-d25d-4070-be98-bfa4992fd6b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1302
        }
      },
      "cell_type": "code",
      "source": [
        "# Let's see the performance of the Naive Bayes Classifier on our subset\n",
        "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
        "test = twenty_test.data\n",
        "X_test_counts = count_vect.transform(test)\n",
        "X_test_tf = tf_transformer.transform(X_test_counts)\n",
        "predicted = naive_bayes_clf.predict(X_test_tf)\n",
        "\n",
        "print(\"Test accuracy:\" + str(np.mean(predicted == twenty_test.target))) \n",
        "print(\"Confusion Matrix:\\n\")\n",
        "print(confusion_matrix(twenty_test.target, predicted))  \n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(twenty_test.target, predicted, target_names=twenty_test.target_names))  \n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:0.03717472118959108\n",
            "Confusion Matrix:\n",
            "\n",
            "[[147  59  64  49   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [232  87  33  37   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [281  61  20  32   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [302  53  11  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [242  70  21  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [257  77  18  43   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [186 103  20  81   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [382   6   2   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [ 24 368   4   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [  3   1 358  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [  0   2   2 395   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [287  49  28  32   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [264  85   9  35   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [185 127  32  52   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [242  52  38  62   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [133  64 107  94   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [194  73  35  62   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [154  40  74 108   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [153  55  42  60   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [ 88  50  63  50   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]]\n",
            "Classification Report:\n",
            "\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alt.atheism       0.04      0.46      0.07       319\n",
            "           comp.graphics       0.06      0.22      0.09       389\n",
            " comp.os.ms-windows.misc       0.02      0.05      0.03       394\n",
            "comp.sys.ibm.pc.hardware       0.02      0.07      0.03       392\n",
            "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
            "          comp.windows.x       0.00      0.00      0.00       395\n",
            "            misc.forsale       0.00      0.00      0.00       390\n",
            "               rec.autos       0.00      0.00      0.00       396\n",
            "         rec.motorcycles       0.00      0.00      0.00       398\n",
            "      rec.sport.baseball       0.00      0.00      0.00       397\n",
            "        rec.sport.hockey       0.00      0.00      0.00       399\n",
            "               sci.crypt       0.00      0.00      0.00       396\n",
            "         sci.electronics       0.00      0.00      0.00       393\n",
            "                 sci.med       0.00      0.00      0.00       396\n",
            "               sci.space       0.00      0.00      0.00       394\n",
            "  soc.religion.christian       0.00      0.00      0.00       398\n",
            "      talk.politics.guns       0.00      0.00      0.00       364\n",
            "   talk.politics.mideast       0.00      0.00      0.00       376\n",
            "      talk.politics.misc       0.00      0.00      0.00       310\n",
            "      talk.religion.misc       0.00      0.00      0.00       251\n",
            "\n",
            "             avg / total       0.01      0.04      0.01      7532\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "AEVSfdTy5Joi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, We try a Logistic Regression Model with Thresholding for classifying text"
      ]
    },
    {
      "metadata": {
        "id": "at2GMbuG5G5-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "log_regression_clf = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial').fit(X_train_tf, twenty_train.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LY57f4z_5coN",
        "colab_type": "code",
        "outputId": "f0fe7818-10ef-4681-af19-9179782886da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1302
        }
      },
      "cell_type": "code",
      "source": [
        "# Let's see the performance of the Logistic Regression Classifier on our subset\n",
        "test = twenty_test.data\n",
        "X_test_counts = count_vect.transform(test)\n",
        "X_test_tf = tf_transformer.transform(X_test_counts)\n",
        "predicted = log_regression_clf.predict(X_test_tf)\n",
        "\n",
        "print(\"Test accuracy:\" + str(np.mean(predicted == twenty_test.target))) \n",
        "print(\"Confusion Matrix:\\n\")\n",
        "print(confusion_matrix(twenty_test.target, predicted))  \n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(twenty_test.target, predicted, target_names=twenty_test.target_names)) "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:0.03983005841741901\n",
            "Confusion Matrix:\n",
            "\n",
            "[[117 138  53  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [195 156  33   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [199 173  19   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [266 107  11   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [222 128  26   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [216 164  14   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [155 192  28  15   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [372  17   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [ 17 377   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [  5   5 363  24   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [  1   7   8 383   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [234 116  37   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [223 152  10   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [156 210  18  12   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [215 126  31  22   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [125 141  92  40   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [170 133  45  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [163 110  65  38   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [165  95  31  19   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [ 76 111  42  22   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]]\n",
            "Classification Report:\n",
            "\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alt.atheism       0.04      0.37      0.06       319\n",
            "           comp.graphics       0.06      0.40      0.10       389\n",
            " comp.os.ms-windows.misc       0.02      0.05      0.03       394\n",
            "comp.sys.ibm.pc.hardware       0.01      0.02      0.02       392\n",
            "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
            "          comp.windows.x       0.00      0.00      0.00       395\n",
            "            misc.forsale       0.00      0.00      0.00       390\n",
            "               rec.autos       0.00      0.00      0.00       396\n",
            "         rec.motorcycles       0.00      0.00      0.00       398\n",
            "      rec.sport.baseball       0.00      0.00      0.00       397\n",
            "        rec.sport.hockey       0.00      0.00      0.00       399\n",
            "               sci.crypt       0.00      0.00      0.00       396\n",
            "         sci.electronics       0.00      0.00      0.00       393\n",
            "                 sci.med       0.00      0.00      0.00       396\n",
            "               sci.space       0.00      0.00      0.00       394\n",
            "  soc.religion.christian       0.00      0.00      0.00       398\n",
            "      talk.politics.guns       0.00      0.00      0.00       364\n",
            "   talk.politics.mideast       0.00      0.00      0.00       376\n",
            "      talk.politics.misc       0.00      0.00      0.00       310\n",
            "      talk.religion.misc       0.00      0.00      0.00       251\n",
            "\n",
            "             avg / total       0.01      0.04      0.01      7532\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q_kkmKsM_SEE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now Let's try using a Perceptron for Classification"
      ]
    },
    {
      "metadata": {
        "id": "XiulRn-UmKjg",
        "colab_type": "code",
        "outputId": "39709cbc-a140-4e3a-c92e-125cc0fb2e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "perceptron_clf = Perceptron(tol=1e-6, random_state=0)\n",
        "perceptron_clf.fit(X_train_tf, twenty_train.target)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
              "      max_iter=None, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
              "      shuffle=True, tol=1e-06, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "YQUjK-7p_Rc_",
        "colab_type": "code",
        "outputId": "cebb598e-3904-4fcd-c5f6-bd05a10d6a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1302
        }
      },
      "cell_type": "code",
      "source": [
        "# Let's see the performance of the Perceptron Classifier on our test\n",
        "test = twenty_test.data\n",
        "X_test_counts = count_vect.transform(test)\n",
        "X_test_tf = tf_transformer.transform(X_test_counts)\n",
        "predicted = perceptron_clf.predict(X_test_tf)\n",
        "\n",
        "print(\"Test accuracy:\" + str(np.mean(predicted == twenty_test.target))) \n",
        "print(\"Confusion Matrix:\\n\")\n",
        "print(confusion_matrix(twenty_test.target, predicted))  \n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(twenty_test.target, predicted, target_names=twenty_test.target_names)) "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:0.03903345724907063\n",
            "Confusion Matrix:\n",
            "\n",
            "[[128  81  83  27   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [203 100  71  15   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [216 113  57   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [280  65  38   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [254  65  47  19   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [246 106  36   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [202 122  41  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [365  17  12   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [ 35 346  15   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [ 10  10 359  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [ 12   4  14 369   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [250  62  52  32   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [230  79  52  32   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [196 131  51  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [226  76  55  37   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [166  96 100  36   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [224  63  55  22   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [219  59  77  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [171  68  49  22   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [ 89  51  68  43   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]]\n",
            "Classification Report:\n",
            "\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alt.atheism       0.03      0.40      0.06       319\n",
            "           comp.graphics       0.06      0.26      0.10       389\n",
            " comp.os.ms-windows.misc       0.04      0.14      0.07       394\n",
            "comp.sys.ibm.pc.hardware       0.01      0.02      0.02       392\n",
            "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
            "          comp.windows.x       0.00      0.00      0.00       395\n",
            "            misc.forsale       0.00      0.00      0.00       390\n",
            "               rec.autos       0.00      0.00      0.00       396\n",
            "         rec.motorcycles       0.00      0.00      0.00       398\n",
            "      rec.sport.baseball       0.00      0.00      0.00       397\n",
            "        rec.sport.hockey       0.00      0.00      0.00       399\n",
            "               sci.crypt       0.00      0.00      0.00       396\n",
            "         sci.electronics       0.00      0.00      0.00       393\n",
            "                 sci.med       0.00      0.00      0.00       396\n",
            "               sci.space       0.00      0.00      0.00       394\n",
            "  soc.religion.christian       0.00      0.00      0.00       398\n",
            "      talk.politics.guns       0.00      0.00      0.00       364\n",
            "   talk.politics.mideast       0.00      0.00      0.00       376\n",
            "      talk.politics.misc       0.00      0.00      0.00       310\n",
            "      talk.religion.misc       0.00      0.00      0.00       251\n",
            "\n",
            "             avg / total       0.01      0.04      0.01      7532\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "2wLhLO57pFAX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, we'll use a decision tree to classify news group"
      ]
    },
    {
      "metadata": {
        "id": "hHYyg3iSpEU3",
        "colab_type": "code",
        "outputId": "1f68d9d0-b165-42c0-dfcb-b077e536d097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        }
      },
      "cell_type": "code",
      "source": [
        "decision_tree_clf = AdaBoostClassifier(DecisionTreeClassifier(),\n",
        "                          n_estimators=300, random_state=0)\n",
        "decision_tree_clf.fit(X_train_tf, twenty_train.target)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R',\n",
              "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
              "            max_features=None, max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
              "            splitter='best'),\n",
              "          learning_rate=1.0, n_estimators=300, random_state=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "IExL_i_5R0-i",
        "colab_type": "code",
        "outputId": "339c281c-0b99-4bc6-d86e-d17f4abbdf0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1320
        }
      },
      "cell_type": "code",
      "source": [
        "# Let's see the performance of the Decision Tree Classifier on our test\n",
        "test = twenty_test.data\n",
        "X_test_counts = count_vect.transform(test)\n",
        "X_test_tf = tf_transformer.transform(X_test_counts)\n",
        "predicted = decision_tree_clf.predict(X_test_tf)\n",
        "\n",
        "print(\"Test accuracy:\" + str(np.mean(predicted == twenty_test.target))) \n",
        "print(\"Confusion Matrix:\\n\")\n",
        "print(confusion_matrix(twenty_test.target, predicted))  \n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(twenty_test.target, predicted, target_names=twenty_test.target_names)) \n",
        "\n",
        "print(twenty_test.target)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy:0.04899097185342539\n",
            "Confusion Matrix:\n",
            "\n",
            "[[163  89  53  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [180 140  46  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [188 147  45  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [200 131  40  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [197 124  41  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [184 152  30  29   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [103 159  61  67   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [284  81  24   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [ 71 308  17   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [ 72  54 216  55   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [ 62  36 101 200   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [165 160  51  20   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [183 148  43  19   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [189 123  62  22   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [161 152  60  21   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [159 122 104  13   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [185 126  43  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [142 123  95  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [138 102  67   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]\n",
            " [115  81  47   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0]]\n",
            "Classification Report:\n",
            "\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "             alt.atheism       0.05      0.51      0.09       319\n",
            "           comp.graphics       0.05      0.36      0.10       389\n",
            " comp.os.ms-windows.misc       0.04      0.11      0.05       394\n",
            "comp.sys.ibm.pc.hardware       0.04      0.05      0.04       392\n",
            "   comp.sys.mac.hardware       0.00      0.00      0.00       385\n",
            "          comp.windows.x       0.00      0.00      0.00       395\n",
            "            misc.forsale       0.00      0.00      0.00       390\n",
            "               rec.autos       0.00      0.00      0.00       396\n",
            "         rec.motorcycles       0.00      0.00      0.00       398\n",
            "      rec.sport.baseball       0.00      0.00      0.00       397\n",
            "        rec.sport.hockey       0.00      0.00      0.00       399\n",
            "               sci.crypt       0.00      0.00      0.00       396\n",
            "         sci.electronics       0.00      0.00      0.00       393\n",
            "                 sci.med       0.00      0.00      0.00       396\n",
            "               sci.space       0.00      0.00      0.00       394\n",
            "  soc.religion.christian       0.00      0.00      0.00       398\n",
            "      talk.politics.guns       0.00      0.00      0.00       364\n",
            "   talk.politics.mideast       0.00      0.00      0.00       376\n",
            "      talk.politics.misc       0.00      0.00      0.00       310\n",
            "      talk.religion.misc       0.00      0.00      0.00       251\n",
            "\n",
            "             avg / total       0.01      0.05      0.01      7532\n",
            "\n",
            "[ 7  5  0 ...  9  6 15]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "SnJftu5VSHqZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "64f7811b-9586-4007-a4db-41b89b8353cf"
      },
      "cell_type": "code",
      "source": [
        "n_classes = 20\n",
        "plot_auc_curve(twenty_test.target, predicted)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-216ef16d011d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_auc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwenty_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-034b8f001550>\u001b[0m in \u001b[0;36mplot_auc_curve\u001b[0;34m(y_test, predicted)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_auc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \"\"\"\n\u001b[1;32m    533\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 534\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    316\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    317\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "5rO20K5Ts9il",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}